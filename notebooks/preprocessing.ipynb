{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/Louis/ml_projects/ToxPost'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"..\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..loading the data..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 81/159570 [00:00<03:28, 765.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..using NLP to clean each comment in the corpus.. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 159570/159570 [02:45<00:00, 966.02it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..writing the results to the cleaned data file\n",
      "..using TfIdf to shrink each comment in the corpus to size 100..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 159570/159570 [03:35<00:00, 739.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..writing the results to the shrunken data file..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5012it [00:00, 50116.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..loading the Glove embedding..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1193515it [00:18, 62906.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using PCA to reduce the embedding space of each word to size 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 159570/159570 [00:07<00:00, 20066.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..writing the results to the embedded data file..\n"
     ]
    }
   ],
   "source": [
    "import src.features.preprocess as preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.features.preprocess as prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'src.features.preprocess' has no attribute 'py'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-de1d94fc5d90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'src.features.preprocess' has no attribute 'py'"
     ]
    }
   ],
   "source": [
    "prep.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..loading the data..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 149/159570 [00:00<03:31, 753.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..using NLP to clean each comment in the corpus.. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 159570/159570 [02:59<00:00, 887.41it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..using TfIdf to shrink each comment in the corpus to size 100..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 159570/159570 [04:03<00:00, 656.66it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-5796d68fe79c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/ml_projects/ToxPost/src/features/preprocess.py\u001b[0m in \u001b[0;36mpreprocess\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mcleaned_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdocument\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcleaned_corpus\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;31m# write the results:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"..writing the results to the cleaned data file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcleaned_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mwr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml_projects/ToxPost/src/features/preprocess.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mcleaned_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdocument\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcleaned_corpus\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;31m# write the results:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"..writing the results to the cleaned data file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcleaned_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mwr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "prep.preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_training_data = \"./data/raw/train.csv\"\n",
    "\n",
    "data = load_corpus(raw_training_data, header=True, id=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [datapoint[0] for datapoint in data]\n",
    "labels = [label[1] for label in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\"l\":1, \"t\":2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[values for values in d.values()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "just to give an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['I', 'tend', 'to', 'think', 'that', 'when', 'the', 'list', 'is', 'longer', 'than', 'the', 'rest', 'of', 'the', 'article,', \"there's\", 'a', 'problem.', 'Either', 'the', 'history', 'and', 'characteristics', 'should', 'be', 'expanded,', 'of', 'the', 'list', 'should', 'be', 'culled.', 'I', 'personally', 'like', 'the', 'consensus', 'that', 'was', 'reached', 'in', 'the', 'Tripel', 'article', 'between', 'and', 'others...myself', 'included.', 'We', 'decided', 'that', 'the', 'country', 'of', 'origin', 'should', 'be', 'highlighted', 'with', 'the', 'most', 'examples.', 'There', 'we', 'did', 'Trappist,', 'Abbey,', 'and', 'Foreign.', 'Foreign', 'includes', 'all', 'non-Belgium', 'examples.', 'This', 'way', 'the', 'article', 'is', 'an', 'article', 'in', 'an', 'encyclopedia,', 'not', 'a', 'list.', 'People', 'can', 'find', 'lists', 'anywhere,', 'and', 'the', 'article', 'should', 'reference', 'this.', 'Also,', 'the', 'style', 'statistics', 'are', 'bad.', 'When', 'you', 'say', 'style', 'statistics,', 'it', 'sounds', 'like', 'a', 'prescription,', 'not', 'a', 'description.', 'An', 'encyclopedia', 'should', 'follow', 'the', 'latter,', 'and', 'if', 'the', 'former', 'is', 'used,', 'a', 'citation', 'should', 'follow...And', \"you'll\", 'not', 'find', 'a', 'valid', 'one', 'for', 'this', 'style', 'in', \"it's\", 'country', 'of', 'origin.'], array([0, 0, 0, 0, 0, 0])]\n"
     ]
    }
   ],
   "source": [
    "print(data[105])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'tend',\n",
       " 'to',\n",
       " 'think',\n",
       " 'that',\n",
       " 'when',\n",
       " 'the',\n",
       " 'list',\n",
       " 'is',\n",
       " 'longer',\n",
       " 'than',\n",
       " 'the',\n",
       " 'rest',\n",
       " 'of',\n",
       " 'the',\n",
       " 'article,',\n",
       " \"there's\",\n",
       " 'a',\n",
       " 'problem.',\n",
       " 'Either',\n",
       " 'the',\n",
       " 'history',\n",
       " 'and',\n",
       " 'characteristics',\n",
       " 'should',\n",
       " 'be',\n",
       " 'expanded,',\n",
       " 'of',\n",
       " 'the',\n",
       " 'list',\n",
       " 'should',\n",
       " 'be',\n",
       " 'culled.',\n",
       " 'I',\n",
       " 'personally',\n",
       " 'like',\n",
       " 'the',\n",
       " 'consensus',\n",
       " 'that',\n",
       " 'was',\n",
       " 'reached',\n",
       " 'in',\n",
       " 'the',\n",
       " 'Tripel',\n",
       " 'article',\n",
       " 'between',\n",
       " 'and',\n",
       " 'others...myself',\n",
       " 'included.',\n",
       " 'We',\n",
       " 'decided',\n",
       " 'that',\n",
       " 'the',\n",
       " 'country',\n",
       " 'of',\n",
       " 'origin',\n",
       " 'should',\n",
       " 'be',\n",
       " 'highlighted',\n",
       " 'with',\n",
       " 'the',\n",
       " 'most',\n",
       " 'examples.',\n",
       " 'There',\n",
       " 'we',\n",
       " 'did',\n",
       " 'Trappist,',\n",
       " 'Abbey,',\n",
       " 'and',\n",
       " 'Foreign.',\n",
       " 'Foreign',\n",
       " 'includes',\n",
       " 'all',\n",
       " 'non-Belgium',\n",
       " 'examples.',\n",
       " 'This',\n",
       " 'way',\n",
       " 'the',\n",
       " 'article',\n",
       " 'is',\n",
       " 'an',\n",
       " 'article',\n",
       " 'in',\n",
       " 'an',\n",
       " 'encyclopedia,',\n",
       " 'not',\n",
       " 'a',\n",
       " 'list.',\n",
       " 'People',\n",
       " 'can',\n",
       " 'find',\n",
       " 'lists',\n",
       " 'anywhere,',\n",
       " 'and',\n",
       " 'the',\n",
       " 'article',\n",
       " 'should',\n",
       " 'reference',\n",
       " 'this.',\n",
       " 'Also,',\n",
       " 'the',\n",
       " 'style',\n",
       " 'statistics',\n",
       " 'are',\n",
       " 'bad.',\n",
       " 'When',\n",
       " 'you',\n",
       " 'say',\n",
       " 'style',\n",
       " 'statistics,',\n",
       " 'it',\n",
       " 'sounds',\n",
       " 'like',\n",
       " 'a',\n",
       " 'prescription,',\n",
       " 'not',\n",
       " 'a',\n",
       " 'description.',\n",
       " 'An',\n",
       " 'encyclopedia',\n",
       " 'should',\n",
       " 'follow',\n",
       " 'the',\n",
       " 'latter,',\n",
       " 'and',\n",
       " 'if',\n",
       " 'the',\n",
       " 'former',\n",
       " 'is',\n",
       " 'used,',\n",
       " 'a',\n",
       " 'citation',\n",
       " 'should',\n",
       " 'follow...And',\n",
       " \"you'll\",\n",
       " 'not',\n",
       " 'find',\n",
       " 'a',\n",
       " 'valid',\n",
       " 'one',\n",
       " 'for',\n",
       " 'this',\n",
       " 'style',\n",
       " 'in',\n",
       " \"it's\",\n",
       " 'country',\n",
       " 'of',\n",
       " 'origin.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[105]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 144.13it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['tend',\n",
       "  'think',\n",
       "  'list',\n",
       "  'longer',\n",
       "  'rest',\n",
       "  'article',\n",
       "  'theres',\n",
       "  'problem',\n",
       "  'either',\n",
       "  'history',\n",
       "  'characteristics',\n",
       "  'expanded',\n",
       "  'list',\n",
       "  'culled',\n",
       "  'personally',\n",
       "  'like',\n",
       "  'consensus',\n",
       "  'reached',\n",
       "  'tripel',\n",
       "  'article',\n",
       "  'othersmyself',\n",
       "  'included',\n",
       "  'decided',\n",
       "  'country',\n",
       "  'origin',\n",
       "  'highlighted',\n",
       "  'examples',\n",
       "  'trappist',\n",
       "  'abbey',\n",
       "  'foreign',\n",
       "  'foreign',\n",
       "  'includes',\n",
       "  'nonbelgium',\n",
       "  'examples',\n",
       "  'way',\n",
       "  'article',\n",
       "  'article',\n",
       "  'encyclopedia',\n",
       "  'list',\n",
       "  'people',\n",
       "  'find',\n",
       "  'lists',\n",
       "  'anywhere',\n",
       "  'article',\n",
       "  'reference',\n",
       "  'also',\n",
       "  'style',\n",
       "  'statistics',\n",
       "  'bad',\n",
       "  'say',\n",
       "  'style',\n",
       "  'statistics',\n",
       "  'sounds',\n",
       "  'like',\n",
       "  'prescription',\n",
       "  'description',\n",
       "  'encyclopedia',\n",
       "  'follow',\n",
       "  'latter',\n",
       "  'former',\n",
       "  'used',\n",
       "  'citation',\n",
       "  'followand',\n",
       "  'youll',\n",
       "  'find',\n",
       "  'valid',\n",
       "  'one',\n",
       "  'style',\n",
       "  'country',\n",
       "  'origin']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_corpus([features[105]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"D'aww!\",\n",
       " 'He',\n",
       " 'matches',\n",
       " 'this',\n",
       " 'background',\n",
       " 'colour',\n",
       " \"I'm\",\n",
       " 'seemingly',\n",
       " 'stuck',\n",
       " 'with.',\n",
       " 'Thanks.',\n",
       " '(talk)',\n",
       " '21:51,',\n",
       " 'January',\n",
       " '11,',\n",
       " '2016',\n",
       " '(UTC)')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 3464/159570 [00:20<03:09, 824.35it/s]"
     ]
    }
   ],
   "source": [
    "features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('I', 'tend', 'to', 'think', 'that', 'when', 'the', 'list', 'is', 'longer', 'than', 'the', 'rest', 'of', 'the', 'article,', \"there's\", 'a', 'problem.', 'Either', 'the', 'history', 'and', 'characteristics', 'should', 'be', 'expanded,', 'of', 'the', 'list', 'should', 'be', 'culled.', 'I', 'personally', 'like', 'the', 'consensus', 'that', 'was', 'reached', 'in', 'the', 'Tripel', 'article', 'between', 'and', 'others...myself', 'included.', 'We', 'decided', 'that', 'the', 'country', 'of', 'origin', 'should', 'be', 'highlighted', 'with', 'the', 'most', 'examples.', 'There', 'we', 'did', 'Trappist,', 'Abbey,', 'and', 'Foreign.', 'Foreign', 'includes', 'all', 'non-Belgium', 'examples.', 'This', 'way', 'the', 'article', 'is', 'an', 'article', 'in', 'an', 'encyclopedia,', 'not', 'a', 'list.', 'People', 'can', 'find', 'lists', 'anywhere,', 'and', 'the', 'article', 'should', 'reference', 'this.', 'Also,', 'the', 'style', 'statistics', 'are', 'bad.', 'When', 'you', 'say', 'style', 'statistics,', 'it', 'sounds', 'like', 'a', 'prescription,', 'not', 'a', 'description.', 'An', 'encyclopedia', 'should', 'follow', 'the', 'latter,', 'and', 'if', 'the', 'former', 'is', 'used,', 'a', 'citation', 'should', 'follow...And', \"you'll\", 'not', 'find', 'a', 'valid', 'one', 'for', 'this', 'style', 'in', \"it's\", 'country', 'of', 'origin.')\n"
     ]
    }
   ],
   "source": [
    "print(features[105])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 159570/159570 [03:00<00:00, 885.03it/s] \n"
     ]
    }
   ],
   "source": [
    "cleaned_features = [clean_document(feature) for feature in tqdm.tqdm(features)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  csv\n",
    "\n",
    "with open(\"out.csv\",\"w\") as f:\n",
    "    wr = csv.writer(f,delimiter=\"\\n\")\n",
    "    wr.writerow(cleaned_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 120/159570 [00:00<02:13, 1195.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfIdf scores calculated...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 159570/159570 [02:13<00:00, 1197.47it/s]\n"
     ]
    }
   ],
   "source": [
    "shrunken_corpus = shrink_corpus(cleaned_features, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove = \"./recourses/glove/glove.twitter.27B.25d.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1193515it [00:22, 53302.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding loaded... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "embedding, embeddable_words = load_embedding(glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "159571it [00:06, 23748.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done reading ./data/raw/train.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 159570/159570 [02:49<00:00, 943.39it/s] \n"
     ]
    }
   ],
   "source": [
    "preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Trappis'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Trappis,\".translate(str.maketrans('', '', string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [\"a\",\"b\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'1': 1, \"2\": 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[values for values in d.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.get(\"3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "la = [1,2,3]\n",
    "lb = [5,6,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = list(zip(la, lb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 5), (2, 6), (3, 7)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "la.index(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [2],\n",
       "       [3]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "la = [1,2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = [4, 5, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "l =[list(item) for item in zip(la, lb)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 4], [2, 5], [3, 6]]\n"
     ]
    }
   ],
   "source": [
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [[a,b] for a in la for b in lb ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 4], [1, 5], [1, 6], [2, 4], [2, 5], [2, 6], [3, 4], [3, 5], [3, 6]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:machine_learning]",
   "language": "python",
   "name": "conda-env-machine_learning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
