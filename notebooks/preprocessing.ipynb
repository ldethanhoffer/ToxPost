{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/Louis/ml_projects/ToxPost'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"..\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.make_dataset import load_data\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We begin by importing the raw data:\n",
    "# Import the raw training data:\n",
    "\n",
    "raw_data_path = \"./data/raw/data.csv\"\n",
    "\n",
    "raw_data = load_data(raw_data_path, header=True, id=True)\n",
    "raw_features = [datapoint[0] for datapoint in data]\n",
    "labels = [datapoint[1] for datapoint in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\" Apologies for my harshness. I do have a temper sometimes. No hard feelings and peace. duck talk \" : [0 0 0 0 0 0]\n",
      "\n",
      "\n",
      "Fool Do you have any evidence that the factual details posted about Courtney Ford are inaccurate? You may have noticed there is no photograph of Courtney Ford (actually, I'm sure you didn't bother to notice). Details of her physical appearance are particularly important in substitute for this omission. Please cease further edits based on your own opinion of how the page should look. Instead, spend your time constructively, such as verifying the posted, ascertainable facts. : [0 0 0 0 0 0]\n",
      "\n",
      "\n",
      "Cate Archer's appearance Cate looks so real, I always thought that there is a real actor behind her as a computer figure. : [0 0 0 0 0 0]\n",
      "\n",
      "\n",
      "- last three paragraphs: : [0 0 0 0 0 0]\n",
      "\n",
      "\n",
      "\"::This sentence is accurate then: approach or approximate means \"\"not quite\"\" expected costs. A good article from the law and economics school on this is Coase's Problem of Social Cost - the eventual outcome will depend, as he points out, on the negotiating skill of the parties. Again, THF has a clear conflict of interest, and his comments should best be disregarded. He is not interested in improving, only trashing this article. \" : [0 0 0 0 0 0]\n",
      "\n",
      "\n",
      "\" Possibly unfree File:Untiltheworld.jpg An image that you uploaded or altered, File:Untiltheworld.jpg, has been listed at Wikipedia:Possibly unfree images because its copyright status is unclear or disputed. If the image's copyright status cannot be verified, it may be deleted. You may find more information on the image description page. You are welcome to add comments to its entry at the discussion if you are interested in it not being deleted. Thank you. (talk) (talk) \" : [0 0 0 0 0 0]\n",
      "\n",
      "\n",
      "\"the term \"\"coon\"\" is not used anymore. the word minstrel should rather be used in the title.\" : [0 0 0 0 0 0]\n",
      "\n",
      "\n",
      "dude whats your problem dude i was being serious on the last one sorry dick head eat my shit : [1 1 1 0 1 0]\n",
      "\n",
      "\n",
      "Hey, Olyeller: Fuck off. : [1 0 1 0 1 0]\n",
      "\n",
      "\n",
      "I would try to contribute more on history and politics. thank you. : [0 0 0 0 0 0]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's look at a few typical datapoints:\n",
    "\n",
    "examples = random.sample(range(0,len(data)),10)\n",
    "\n",
    "for i in examples:\n",
    "    print(\" \".join(features[i]),\":\", labels[i])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "We'll begin by cleaning up the data:\n",
    "\n",
    "1. tokenize  \n",
    "2. remove numbers, links, punctuation and articles\n",
    "3. remove stopwords as defined in nltk.stopwords\n",
    "4. replace words using a custom list  \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..loading the data..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 81/159570 [00:00<03:28, 765.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..using NLP to clean each comment in the corpus.. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 159570/159570 [02:45<00:00, 966.02it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..writing the results to the cleaned data file\n",
      "..using TfIdf to shrink each comment in the corpus to size 100..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 159570/159570 [03:35<00:00, 739.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..writing the results to the shrunken data file..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5012it [00:00, 50116.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..loading the Glove embedding..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1193515it [00:18, 62906.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using PCA to reduce the embedding space of each word to size 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 159570/159570 [00:07<00:00, 20066.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..writing the results to the embedded data file..\n",
      "..data preprocesssed..\n"
     ]
    }
   ],
   "source": [
    "import src.features.preprocess as preprocess"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:machine_learning]",
   "language": "python",
   "name": "conda-env-machine_learning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
